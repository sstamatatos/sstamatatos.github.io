{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SebDaddy ðŸ¤ª",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sstamatatos/sstamatatos.github.io/blob/master/SebDaddy_%F0%9F%A4%AA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nSOCc98CQOT",
        "colab_type": "code",
        "outputId": "ecca6295-c6a5-4c80-8d56-080888400c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "# Initial Import Libararies\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader as web\n",
        "from pandas import concat\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-StZMJOtCq1T",
        "colab_type": "code",
        "outputId": "3b9266a2-f035-4a2c-b2aa-9ea2dfb20286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Parameters:\n",
        "tickerID = \"MSFT\" #@param {type:\"string\"}\n",
        "startDate = \"2000-01-01\" #@param {type:\"date\"}\n",
        "\n",
        "# Get Desired Stock Data\n",
        "rawdf = web.DataReader(tickerID, data_source='yahoo', start=startDate)\n",
        "\n",
        "# Show the data\n",
        "rawdf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>59.312500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>58.687500</td>\n",
              "      <td>58.281250</td>\n",
              "      <td>53228400.0</td>\n",
              "      <td>37.495686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>58.562500</td>\n",
              "      <td>56.125000</td>\n",
              "      <td>56.781250</td>\n",
              "      <td>56.312500</td>\n",
              "      <td>54119000.0</td>\n",
              "      <td>36.229057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>58.187500</td>\n",
              "      <td>54.687500</td>\n",
              "      <td>55.562500</td>\n",
              "      <td>56.906250</td>\n",
              "      <td>64059600.0</td>\n",
              "      <td>36.611080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>56.937500</td>\n",
              "      <td>54.187500</td>\n",
              "      <td>56.093750</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>54976600.0</td>\n",
              "      <td>35.384666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>56.125000</td>\n",
              "      <td>53.656250</td>\n",
              "      <td>54.312500</td>\n",
              "      <td>55.718750</td>\n",
              "      <td>62013600.0</td>\n",
              "      <td>35.847076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-11</th>\n",
              "      <td>190.699997</td>\n",
              "      <td>183.500000</td>\n",
              "      <td>190.649994</td>\n",
              "      <td>184.440002</td>\n",
              "      <td>53159900.0</td>\n",
              "      <td>184.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-12</th>\n",
              "      <td>185.850006</td>\n",
              "      <td>181.850006</td>\n",
              "      <td>185.580002</td>\n",
              "      <td>184.710007</td>\n",
              "      <td>47062900.0</td>\n",
              "      <td>184.710007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-13</th>\n",
              "      <td>186.229996</td>\n",
              "      <td>182.869995</td>\n",
              "      <td>183.080002</td>\n",
              "      <td>183.710007</td>\n",
              "      <td>35295800.0</td>\n",
              "      <td>183.710007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-14</th>\n",
              "      <td>185.410004</td>\n",
              "      <td>182.649994</td>\n",
              "      <td>183.250000</td>\n",
              "      <td>185.350006</td>\n",
              "      <td>23149500.0</td>\n",
              "      <td>185.350006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-18</th>\n",
              "      <td>187.699997</td>\n",
              "      <td>185.500000</td>\n",
              "      <td>185.610001</td>\n",
              "      <td>187.229996</td>\n",
              "      <td>27792200.0</td>\n",
              "      <td>187.229996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5063 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  High         Low  ...      Volume   Adj Close\n",
              "Date                                ...                        \n",
              "2000-01-03   59.312500   56.000000  ...  53228400.0   37.495686\n",
              "2000-01-04   58.562500   56.125000  ...  54119000.0   36.229057\n",
              "2000-01-05   58.187500   54.687500  ...  64059600.0   36.611080\n",
              "2000-01-06   56.937500   54.187500  ...  54976600.0   35.384666\n",
              "2000-01-07   56.125000   53.656250  ...  62013600.0   35.847076\n",
              "...                ...         ...  ...         ...         ...\n",
              "2020-02-11  190.699997  183.500000  ...  53159900.0  184.440002\n",
              "2020-02-12  185.850006  181.850006  ...  47062900.0  184.710007\n",
              "2020-02-13  186.229996  182.869995  ...  35295800.0  183.710007\n",
              "2020-02-14  185.410004  182.649994  ...  23149500.0  185.350006\n",
              "2020-02-18  187.699997  185.500000  ...  27792200.0  187.229996\n",
              "\n",
              "[5063 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOS_JD6LCzj1",
        "colab_type": "code",
        "outputId": "1156ae6b-f0e1-4f17-b4ba-7ab8bb5e74ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# Visualize Raw Adj Close Data\n",
        "plt.plot(rawdf['Adj Close'])\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
            "\n",
            "To register the converters:\n",
            "\t>>> from pandas.plotting import register_matplotlib_converters\n",
            "\t>>> register_matplotlib_converters()\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEJCAYAAADbzlMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIDmxN5BC5id",
        "colab_type": "code",
        "outputId": "3d2189a4-af3a-4084-dd73-1b00c486ce3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Drop Close Column\n",
        "rawdf = rawdf.drop(columns='Close')\n",
        "\n",
        "#Show Raw Data\n",
        "rawdf"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>59.312500</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>58.687500</td>\n",
              "      <td>53228400.0</td>\n",
              "      <td>37.495686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>58.562500</td>\n",
              "      <td>56.125000</td>\n",
              "      <td>56.781250</td>\n",
              "      <td>54119000.0</td>\n",
              "      <td>36.229057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>58.187500</td>\n",
              "      <td>54.687500</td>\n",
              "      <td>55.562500</td>\n",
              "      <td>64059600.0</td>\n",
              "      <td>36.611080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>56.937500</td>\n",
              "      <td>54.187500</td>\n",
              "      <td>56.093750</td>\n",
              "      <td>54976600.0</td>\n",
              "      <td>35.384666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>56.125000</td>\n",
              "      <td>53.656250</td>\n",
              "      <td>54.312500</td>\n",
              "      <td>62013600.0</td>\n",
              "      <td>35.847076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-11</th>\n",
              "      <td>190.699997</td>\n",
              "      <td>183.500000</td>\n",
              "      <td>190.649994</td>\n",
              "      <td>53159900.0</td>\n",
              "      <td>184.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-12</th>\n",
              "      <td>185.850006</td>\n",
              "      <td>181.850006</td>\n",
              "      <td>185.580002</td>\n",
              "      <td>47062900.0</td>\n",
              "      <td>184.710007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-13</th>\n",
              "      <td>186.229996</td>\n",
              "      <td>182.869995</td>\n",
              "      <td>183.080002</td>\n",
              "      <td>35295800.0</td>\n",
              "      <td>183.710007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-14</th>\n",
              "      <td>185.410004</td>\n",
              "      <td>182.649994</td>\n",
              "      <td>183.250000</td>\n",
              "      <td>23149500.0</td>\n",
              "      <td>185.350006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-02-18</th>\n",
              "      <td>187.699997</td>\n",
              "      <td>185.500000</td>\n",
              "      <td>185.610001</td>\n",
              "      <td>27792200.0</td>\n",
              "      <td>187.229996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5063 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  High         Low        Open      Volume   Adj Close\n",
              "Date                                                                  \n",
              "2000-01-03   59.312500   56.000000   58.687500  53228400.0   37.495686\n",
              "2000-01-04   58.562500   56.125000   56.781250  54119000.0   36.229057\n",
              "2000-01-05   58.187500   54.687500   55.562500  64059600.0   36.611080\n",
              "2000-01-06   56.937500   54.187500   56.093750  54976600.0   35.384666\n",
              "2000-01-07   56.125000   53.656250   54.312500  62013600.0   35.847076\n",
              "...                ...         ...         ...         ...         ...\n",
              "2020-02-11  190.699997  183.500000  190.649994  53159900.0  184.440002\n",
              "2020-02-12  185.850006  181.850006  185.580002  47062900.0  184.710007\n",
              "2020-02-13  186.229996  182.869995  183.080002  35295800.0  183.710007\n",
              "2020-02-14  185.410004  182.649994  183.250000  23149500.0  185.350006\n",
              "2020-02-18  187.699997  185.500000  185.610001  27792200.0  187.229996\n",
              "\n",
              "[5063 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFndRvddC-eO",
        "colab_type": "code",
        "outputId": "dade8692-8194-45ea-8d30-d02486ee1c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# Convert to numpy array\n",
        "data = np.array(rawdf)\n",
        "\n",
        "# Show Data\n",
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.93125000e+01, 5.60000000e+01, 5.86875000e+01, 5.32284000e+07,\n",
              "        3.74956856e+01],\n",
              "       [5.85625000e+01, 5.61250000e+01, 5.67812500e+01, 5.41190000e+07,\n",
              "        3.62290573e+01],\n",
              "       [5.81875000e+01, 5.46875000e+01, 5.55625000e+01, 6.40596000e+07,\n",
              "        3.66110802e+01],\n",
              "       ...,\n",
              "       [1.86229996e+02, 1.82869995e+02, 1.83080002e+02, 3.52958000e+07,\n",
              "        1.83710007e+02],\n",
              "       [1.85410004e+02, 1.82649994e+02, 1.83250000e+02, 2.31495000e+07,\n",
              "        1.85350006e+02],\n",
              "       [1.87699997e+02, 1.85500000e+02, 1.85610001e+02, 2.77922000e+07,\n",
              "        1.87229996e+02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz48za8sDGb5",
        "colab_type": "code",
        "outputId": "61ceee18-7db4-40fc-9ceb-9d1b2ac5407c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Split the Data into X and Y\n",
        "x_data = data[:, :4]\n",
        "y_data = data[:, 4]\n",
        "\n",
        "x_data, y_data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[5.93125000e+01, 5.60000000e+01, 5.86875000e+01, 5.32284000e+07],\n",
              "        [5.85625000e+01, 5.61250000e+01, 5.67812500e+01, 5.41190000e+07],\n",
              "        [5.81875000e+01, 5.46875000e+01, 5.55625000e+01, 6.40596000e+07],\n",
              "        ...,\n",
              "        [1.86229996e+02, 1.82869995e+02, 1.83080002e+02, 3.52958000e+07],\n",
              "        [1.85410004e+02, 1.82649994e+02, 1.83250000e+02, 2.31495000e+07],\n",
              "        [1.87699997e+02, 1.85500000e+02, 1.85610001e+02, 2.77922000e+07]]),\n",
              " array([ 37.49568558,  36.22905731,  36.61108017, ..., 183.71000671,\n",
              "        185.3500061 , 187.22999573]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0Cm-TQwDPhA",
        "colab_type": "code",
        "outputId": "708f755b-76e5-47a6-8003-eaa21a5bf853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Reshape Y Data\n",
        "y_data = np.reshape(y_data, (y_data.shape[0], 1))\n",
        "\n",
        "y_data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5063, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vs4Iq3SDtek",
        "colab_type": "code",
        "outputId": "a5fe93d9-2422-418f-dfe6-155532f7c6d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "# Scale the Data\n",
        "xscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "yscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "x_data_scaled = xscaler.fit_transform(x_data)\n",
        "y_data_scaled = yscaler.fit_transform(y_data)\n",
        "\n",
        "x_data_scaled, y_data_scaled"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.24955735, 0.24104788, 0.24786265, 0.07847963],\n",
              "        [0.24527359, 0.24178046, 0.23699773, 0.08000561],\n",
              "        [0.24313172, 0.2333558 , 0.23005131, 0.09703807],\n",
              "        ...,\n",
              "        [0.97446881, 0.9845865 , 0.95685385, 0.04775348],\n",
              "        [0.96978528, 0.98329716, 0.95782277, 0.02694171],\n",
              "        [0.98286498, 1.        , 0.9712739 , 0.03489663]]),\n",
              " array([[0.14558775],\n",
              "        [0.1384304 ],\n",
              "        [0.1405891 ],\n",
              "        ...,\n",
              "        [0.97180299],\n",
              "        [0.98107016],\n",
              "        [0.99169344]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLfQRCN9Duif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "numDays =  15#@param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKDcqWA0Dz2P",
        "colab_type": "code",
        "outputId": "191edabf-1044-49b8-c2d5-0335f36a3137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Create X and Y Train Data\n",
        "x_train = x_data_scaled[:x_data_scaled.shape[0] - numDays]\n",
        "y_train = y_data_scaled[numDays:]\n",
        "\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5048, 4), (5048, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yggq_0MGD8ym",
        "colab_type": "code",
        "outputId": "1a790328-6090-40ea-bf3f-d2c2d47bc992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Reshape X Data\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5048, 4, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cun7d4r4EAeJ",
        "colab_type": "code",
        "outputId": "a87bef29-7755-40d1-a3e7-c354e5b97684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# Build LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], \n",
        "                                                       x_train.shape[2])))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUBBr_WXEDt0",
        "colab_type": "code",
        "outputId": "5a663ca3-9d97-498a-804d-ab2b2fbd2962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAVdlcE8EHIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape Scaled Data\n",
        "x_data_scaled = np.reshape(x_data_scaled, (x_data_scaled.shape[0], x_data_scaled.shape[1], 1))\n",
        "y_data_scaled = np.reshape(y_data_scaled, (y_data_scaled.shape[0], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3DQzXQOEKaR",
        "colab_type": "code",
        "outputId": "2dffd2b0-a66f-4fbe-ac2a-ae0615b7fc19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(x=x_train, y=y_train, validation_data=(x_data_scaled[:x_data_scaled.shape[0] - numDays], y_data_scaled[numDays:]), batch_size=50, epochs=numDays*4, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 5048 samples, validate on 5048 samples\n",
            "Epoch 1/60\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "5048/5048 [==============================] - 4s 716us/step - loss: 6.2708e-04 - val_loss: 0.1187\n",
            "Epoch 2/60\n",
            "5048/5048 [==============================] - 2s 339us/step - loss: 0.0070 - val_loss: 0.2538\n",
            "Epoch 3/60\n",
            "5048/5048 [==============================] - 2s 325us/step - loss: 0.0157 - val_loss: 0.4171\n",
            "Epoch 4/60\n",
            "5048/5048 [==============================] - 2s 347us/step - loss: 0.0359 - val_loss: 0.0966\n",
            "Epoch 5/60\n",
            "5048/5048 [==============================] - 2s 335us/step - loss: 0.0326 - val_loss: 0.0460\n",
            "Epoch 6/60\n",
            "5048/5048 [==============================] - 2s 347us/step - loss: 0.0118 - val_loss: 0.0285\n",
            "Epoch 7/60\n",
            "5048/5048 [==============================] - 2s 343us/step - loss: 0.0045 - val_loss: 0.0084\n",
            "Epoch 8/60\n",
            "5048/5048 [==============================] - 2s 348us/step - loss: 0.0028 - val_loss: 0.0231\n",
            "Epoch 9/60\n",
            "5048/5048 [==============================] - 2s 347us/step - loss: 0.0058 - val_loss: 0.0232\n",
            "Epoch 10/60\n",
            "5048/5048 [==============================] - 2s 341us/step - loss: 0.0043 - val_loss: 0.0130\n",
            "Epoch 11/60\n",
            "5048/5048 [==============================] - 2s 331us/step - loss: 0.0037 - val_loss: 0.0190\n",
            "Epoch 12/60\n",
            "5048/5048 [==============================] - 2s 337us/step - loss: 0.0039 - val_loss: 0.0143\n",
            "Epoch 13/60\n",
            "5048/5048 [==============================] - 2s 344us/step - loss: 0.0031 - val_loss: 0.0134\n",
            "Epoch 14/60\n",
            "5048/5048 [==============================] - 2s 353us/step - loss: 0.0028 - val_loss: 0.0120\n",
            "Epoch 15/60\n",
            "5048/5048 [==============================] - 2s 339us/step - loss: 0.0025 - val_loss: 0.0107\n",
            "Epoch 16/60\n",
            "5048/5048 [==============================] - 2s 348us/step - loss: 0.0022 - val_loss: 0.0096\n",
            "Epoch 17/60\n",
            "5048/5048 [==============================] - 2s 341us/step - loss: 0.0019 - val_loss: 0.0083\n",
            "Epoch 18/60\n",
            "5048/5048 [==============================] - 2s 348us/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 19/60\n",
            "5048/5048 [==============================] - 2s 334us/step - loss: 0.0016 - val_loss: 0.0046\n",
            "Epoch 20/60\n",
            "5048/5048 [==============================] - 2s 334us/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 21/60\n",
            "5048/5048 [==============================] - 2s 332us/step - loss: 0.0018 - val_loss: 0.0085\n",
            "Epoch 22/60\n",
            "5048/5048 [==============================] - 2s 332us/step - loss: 0.0022 - val_loss: 0.0091\n",
            "Epoch 23/60\n",
            "5048/5048 [==============================] - 2s 333us/step - loss: 0.0024 - val_loss: 0.0096\n",
            "Epoch 24/60\n",
            "5048/5048 [==============================] - 2s 336us/step - loss: 0.0026 - val_loss: 0.0100\n",
            "Epoch 25/60\n",
            "5048/5048 [==============================] - 2s 349us/step - loss: 0.0027 - val_loss: 0.0104\n",
            "Epoch 26/60\n",
            "5048/5048 [==============================] - 2s 351us/step - loss: 0.0028 - val_loss: 0.0116\n",
            "Epoch 27/60\n",
            "5048/5048 [==============================] - 2s 351us/step - loss: 0.0029 - val_loss: 0.0144\n",
            "Epoch 28/60\n",
            "5048/5048 [==============================] - 2s 348us/step - loss: 0.0033 - val_loss: 0.0170\n",
            "Epoch 29/60\n",
            "5048/5048 [==============================] - 2s 343us/step - loss: 0.0033 - val_loss: 0.0148\n",
            "Epoch 30/60\n",
            "5048/5048 [==============================] - 2s 352us/step - loss: 0.0031 - val_loss: 0.0101\n",
            "Epoch 31/60\n",
            "5048/5048 [==============================] - 2s 352us/step - loss: 0.0027 - val_loss: 0.0084\n",
            "Epoch 32/60\n",
            "5048/5048 [==============================] - 2s 350us/step - loss: 0.0026 - val_loss: 0.0080\n",
            "Epoch 33/60\n",
            "5048/5048 [==============================] - 2s 348us/step - loss: 0.0025 - val_loss: 0.0080\n",
            "Epoch 34/60\n",
            "5048/5048 [==============================] - 2s 342us/step - loss: 0.0026 - val_loss: 0.0082\n",
            "Epoch 35/60\n",
            "2050/5048 [===========>..................] - ETA: 0s - loss: 0.0037"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDJyVDvaEob6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Forecast Values\n",
        "xforecast = x_data_scaled[x_data_scaled.shape[0] - numDays:]\n",
        "xforecast = np.reshape(xforecast, (xforecast.shape[0], xforecast.shape[1], 1))\n",
        "\n",
        "# Get Forecast\n",
        "forecast = model.predict(xforecast)\n",
        "forecast = yscaler.inverse_transform(forecast)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8KtOgNBEt0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize Forecast\n",
        "plt.plot(forecast)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}